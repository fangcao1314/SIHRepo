{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import keras as ks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Embedding, LSTM,Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=['HR',\n",
    " 'O2Sat',\n",
    " 'Temp',\n",
    " 'SBP',\n",
    " 'MAP',\n",
    " 'DBP',\n",
    " 'Resp',\n",
    " 'BaseExcess',\n",
    " 'HCO3',\n",
    " 'FiO2',\n",
    " 'pH',\n",
    " 'PaCO2',\n",
    " 'AST',\n",
    " 'BUN',\n",
    " 'Calcium',\n",
    " 'Chloride',\n",
    " 'Glucose',\n",
    " 'Magnesium',\n",
    " 'Potassium',\n",
    " 'Hct',\n",
    " 'Hgb',\n",
    " 'WBC',\n",
    " 'Age',\n",
    " 'Gender',\n",
    " 'Unit1',\n",
    " 'Unit2',\n",
    " 'HospAdmTime',\n",
    " 'ICULOS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    " def create_larger():\n",
    "        model = Sequential()\n",
    "        model.add(Dense(80,input_dim=28,activation='relu'))\n",
    "        model.add(Dense(120,activation='relu'))\n",
    "        model.add(Dense(120,activation='relu'))\n",
    "        model.add(Dense(120,activation='relu'))\n",
    "        model.add(Dense(120,activation='relu'))\n",
    "        model.add(Dense(120,activation='relu'))\n",
    "        model.add(Dense(120,activation='relu'))\n",
    "        model.add(Dense(120,activation='relu'))\n",
    "        model.add(Dense(120,activation='relu'))\n",
    "        model.add(Dense(120,activation='relu'))\n",
    "        model.add(Dense(120,activation='relu'))\n",
    "        model.add(Dense(120,activation='relu'))\n",
    "        model.add(Dense(120,activation='relu'))\n",
    "        model.add(Dense(120,activation='relu'))\n",
    "        model.add(Dense(120,activation='relu'))\n",
    "        model.add(Dense(120,activation='relu'))\n",
    "        model.add(Dense(120,activation='relu'))\n",
    "        model.add(Dense(120,activation='relu'))\n",
    "        model.add(Dense(120,activation='relu'))\n",
    "        model.add(Dense(120,activation='relu'))\n",
    "        model.add(Dense(120,activation='relu'))\n",
    "        model.add(Dense(120,activation='relu'))\n",
    "        model.add(Dense(120,activation='relu'))\n",
    "        model.add(Dense(120,activation='relu'))\n",
    "        model.add(Dense(120,activation='relu'))\n",
    "        \n",
    "        \n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        model.compile(loss='binary_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\sourabh\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "model=create_larger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['HR',\n",
       " 'O2Sat',\n",
       " 'Temp',\n",
       " 'SBP',\n",
       " 'MAP',\n",
       " 'DBP',\n",
       " 'Resp',\n",
       " 'BaseExcess',\n",
       " 'HCO3',\n",
       " 'FiO2',\n",
       " 'pH',\n",
       " 'PaCO2',\n",
       " 'AST',\n",
       " 'BUN',\n",
       " 'Calcium',\n",
       " 'Chloride',\n",
       " 'Glucose',\n",
       " 'Magnesium',\n",
       " 'Potassium',\n",
       " 'Hct',\n",
       " 'Hgb',\n",
       " 'WBC',\n",
       " 'Age',\n",
       " 'Gender',\n",
       " 'Unit1',\n",
       " 'Unit2',\n",
       " 'HospAdmTime',\n",
       " 'ICULOS']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('./SetA/setAE.csv')\n",
    "\n",
    "\n",
    "data=data.fillna(0)\n",
    "\n",
    "\n",
    "X=data[x].copy()\n",
    "y=data['SepsisLabel'].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>HR</th>\n",
       "      <th>O2Sat</th>\n",
       "      <th>Temp</th>\n",
       "      <th>SBP</th>\n",
       "      <th>MAP</th>\n",
       "      <th>DBP</th>\n",
       "      <th>Resp</th>\n",
       "      <th>EtCO2</th>\n",
       "      <th>BaseExcess</th>\n",
       "      <th>...</th>\n",
       "      <th>WBC</th>\n",
       "      <th>Fibrinogen</th>\n",
       "      <th>Platelets</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Unit1</th>\n",
       "      <th>Unit2</th>\n",
       "      <th>HospAdmTime</th>\n",
       "      <th>ICULOS</th>\n",
       "      <th>SepsisLabel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>83.14</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>97.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>75.33</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>83.14</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>89.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>86.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>83.14</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>90.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>83.14</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>103.0</td>\n",
       "      <td>88.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>91.33</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>83.14</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>666762</td>\n",
       "      <td>18</td>\n",
       "      <td>78.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>37.2</td>\n",
       "      <td>134.0</td>\n",
       "      <td>67.00</td>\n",
       "      <td>47.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>67.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-3.87</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>666763</td>\n",
       "      <td>19</td>\n",
       "      <td>83.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>37.2</td>\n",
       "      <td>129.5</td>\n",
       "      <td>70.00</td>\n",
       "      <td>49.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>67.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-3.87</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>666764</td>\n",
       "      <td>20</td>\n",
       "      <td>81.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>37.2</td>\n",
       "      <td>124.0</td>\n",
       "      <td>67.00</td>\n",
       "      <td>46.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>67.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-3.87</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>666765</td>\n",
       "      <td>21</td>\n",
       "      <td>84.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>69.00</td>\n",
       "      <td>48.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>67.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-3.87</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>666766</td>\n",
       "      <td>22</td>\n",
       "      <td>85.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>65.00</td>\n",
       "      <td>45.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>67.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-3.87</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>666767 rows Ã— 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0     HR  O2Sat  Temp    SBP    MAP   DBP  Resp  EtCO2  \\\n",
       "0                0    0.0    0.0   0.0    0.0   0.00   0.0   0.0    0.0   \n",
       "1                1   97.0   95.0   0.0   98.0  75.33   0.0  19.0    0.0   \n",
       "2                2   89.0   99.0   0.0  122.0  86.00   0.0  22.0    0.0   \n",
       "3                3   90.0   95.0   0.0    0.0   0.00   0.0  30.0    0.0   \n",
       "4                4  103.0   88.5   0.0  122.0  91.33   0.0  24.5    0.0   \n",
       "...            ...    ...    ...   ...    ...    ...   ...   ...    ...   \n",
       "666762          18   78.0   97.0  37.2  134.0  67.00  47.0  11.0    0.0   \n",
       "666763          19   83.0   97.0  37.2  129.5  70.00  49.0  14.0    0.0   \n",
       "666764          20   81.0   97.0  37.2  124.0  67.00  46.0  12.0    0.0   \n",
       "666765          21   84.0   97.0   0.0  133.0  69.00  48.0  16.0    0.0   \n",
       "666766          22   85.0   96.0   0.0  124.0  65.00  45.0  17.0    0.0   \n",
       "\n",
       "        BaseExcess  ...  WBC  Fibrinogen  Platelets    Age  Gender  Unit1  \\\n",
       "0              0.0  ...  0.0         0.0        0.0  83.14       0    0.0   \n",
       "1              0.0  ...  0.0         0.0        0.0  83.14       0    0.0   \n",
       "2              0.0  ...  0.0         0.0        0.0  83.14       0    0.0   \n",
       "3             24.0  ...  0.0         0.0        0.0  83.14       0    0.0   \n",
       "4              0.0  ...  0.0         0.0        0.0  83.14       0    0.0   \n",
       "...            ...  ...  ...         ...        ...    ...     ...    ...   \n",
       "666762         0.0  ...  0.0         0.0        0.0  67.86       1    0.0   \n",
       "666763         0.0  ...  0.0         0.0        0.0  67.86       1    0.0   \n",
       "666764         0.0  ...  0.0         0.0        0.0  67.86       1    0.0   \n",
       "666765         0.0  ...  0.0         0.0        0.0  67.86       1    0.0   \n",
       "666766         0.0  ...  0.0         0.0        0.0  67.86       1    0.0   \n",
       "\n",
       "        Unit2  HospAdmTime  ICULOS  SepsisLabel  \n",
       "0         0.0        -0.03       1            0  \n",
       "1         0.0        -0.03       2            0  \n",
       "2         0.0        -0.03       3            0  \n",
       "3         0.0        -0.03       4            0  \n",
       "4         0.0        -0.03       5            0  \n",
       "...       ...          ...     ...          ...  \n",
       "666762    1.0        -3.87      19            0  \n",
       "666763    1.0        -3.87      20            0  \n",
       "666764    1.0        -3.87      21            0  \n",
       "666765    1.0        -3.87      22            0  \n",
       "666766    1.0        -3.87      23            0  \n",
       "\n",
       "[666767 rows x 42 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=X.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\sourabh\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/200\n",
      "40827/40827 [==============================] - 15s 361us/step - loss: 0.6695 - accuracy: 0.6243\n",
      "Epoch 2/200\n",
      "40827/40827 [==============================] - 10s 235us/step - loss: 0.6573 - accuracy: 0.6262\n",
      "Epoch 3/200\n",
      "40827/40827 [==============================] - 8s 207us/step - loss: 0.6433 - accuracy: 0.62620s - loss: 0.6437 \n",
      "Epoch 4/200\n",
      "40827/40827 [==============================] - 8s 206us/step - loss: 0.6192 - accuracy: 0.6262\n",
      "Epoch 5/200\n",
      "40827/40827 [==============================] - 8s 200us/step - loss: 0.6037 - accuracy: 0.7030\n",
      "Epoch 6/200\n",
      "40827/40827 [==============================] - 9s 224us/step - loss: 0.5902 - accuracy: 0.7170\n",
      "Epoch 7/200\n",
      "40827/40827 [==============================] - 8s 205us/step - loss: 0.5841 - accuracy: 0.7239\n",
      "Epoch 8/200\n",
      "40827/40827 [==============================] - 8s 201us/step - loss: 0.5730 - accuracy: 0.7300\n",
      "Epoch 9/200\n",
      "40827/40827 [==============================] - 8s 193us/step - loss: 0.5629 - accuracy: 0.7352\n",
      "Epoch 10/200\n",
      "40827/40827 [==============================] - 8s 193us/step - loss: 0.5600 - accuracy: 0.7395\n",
      "Epoch 11/200\n",
      "40827/40827 [==============================] - 10s 233us/step - loss: 0.5501 - accuracy: 0.7404\n",
      "Epoch 12/200\n",
      "40827/40827 [==============================] - 8s 203us/step - loss: 0.5432 - accuracy: 0.7430\n",
      "Epoch 13/200\n",
      "40827/40827 [==============================] - 9s 211us/step - loss: 0.5385 - accuracy: 0.7458\n",
      "Epoch 14/200\n",
      "40827/40827 [==============================] - 9s 210us/step - loss: 0.5325 - accuracy: 0.7485\n",
      "Epoch 15/200\n",
      "40827/40827 [==============================] - 9s 211us/step - loss: 0.5327 - accuracy: 0.74973s - loss: - ETA: 0s - loss: 0.5331 - \n",
      "Epoch 16/200\n",
      "40827/40827 [==============================] - 8s 195us/step - loss: 0.5281 - accuracy: 0.7523\n",
      "Epoch 17/200\n",
      "40827/40827 [==============================] - 9s 216us/step - loss: 0.5230 - accuracy: 0.7544\n",
      "Epoch 18/200\n",
      "40827/40827 [==============================] - 9s 216us/step - loss: 0.5187 - accuracy: 0.7533\n",
      "Epoch 19/200\n",
      "40827/40827 [==============================] - 8s 205us/step - loss: 0.5178 - accuracy: 0.7563\n",
      "Epoch 20/200\n",
      "40827/40827 [==============================] - 9s 216us/step - loss: 0.5123 - accuracy: 0.7590\n",
      "Epoch 21/200\n",
      "40827/40827 [==============================] - 9s 219us/step - loss: 0.5109 - accuracy: 0.7584\n",
      "Epoch 22/200\n",
      "40827/40827 [==============================] - 9s 212us/step - loss: 0.5069 - accuracy: 0.7609\n",
      "Epoch 23/200\n",
      "40827/40827 [==============================] - 9s 211us/step - loss: 0.5027 - accuracy: 0.7619\n",
      "Epoch 24/200\n",
      "40827/40827 [==============================] - 8s 199us/step - loss: 0.5025 - accuracy: 0.7626\n",
      "Epoch 25/200\n",
      "40827/40827 [==============================] - 9s 215us/step - loss: 0.4999 - accuracy: 0.7650\n",
      "Epoch 26/200\n",
      "40827/40827 [==============================] - 9s 213us/step - loss: 0.4954 - accuracy: 0.7688\n",
      "Epoch 27/200\n",
      "40827/40827 [==============================] - 8s 202us/step - loss: 0.4931 - accuracy: 0.7672\n",
      "Epoch 28/200\n",
      "40827/40827 [==============================] - 9s 220us/step - loss: 0.4902 - accuracy: 0.7704\n",
      "Epoch 29/200\n",
      "40827/40827 [==============================] - 9s 212us/step - loss: 0.4854 - accuracy: 0.7729\n",
      "Epoch 30/200\n",
      "40827/40827 [==============================] - 8s 197us/step - loss: 0.4836 - accuracy: 0.7745\n",
      "Epoch 31/200\n",
      "40827/40827 [==============================] - 9s 212us/step - loss: 0.4828 - accuracy: 0.7732\n",
      "Epoch 32/200\n",
      "40827/40827 [==============================] - 9s 209us/step - loss: 0.4783 - accuracy: 0.7775\n",
      "Epoch 33/200\n",
      "40827/40827 [==============================] - 8s 192us/step - loss: 0.4768 - accuracy: 0.7777\n",
      "Epoch 34/200\n",
      "40827/40827 [==============================] - 9s 208us/step - loss: 0.4722 - accuracy: 0.7814\n",
      "Epoch 35/200\n",
      "40827/40827 [==============================] - 9s 212us/step - loss: 0.4719 - accuracy: 0.7797\n",
      "Epoch 36/200\n",
      "40827/40827 [==============================] - 9s 210us/step - loss: 0.4677 - accuracy: 0.7835\n",
      "Epoch 37/200\n",
      "40827/40827 [==============================] - 8s 207us/step - loss: 0.4642 - accuracy: 0.7848\n",
      "Epoch 38/200\n",
      "40827/40827 [==============================] - 8s 208us/step - loss: 0.4616 - accuracy: 0.7874\n",
      "Epoch 39/200\n",
      "40827/40827 [==============================] - 9s 212us/step - loss: 0.4616 - accuracy: 0.7873\n",
      "Epoch 40/200\n",
      "40827/40827 [==============================] - 8s 192us/step - loss: 0.4573 - accuracy: 0.7901\n",
      "Epoch 41/200\n",
      "40827/40827 [==============================] - 8s 205us/step - loss: 0.4543 - accuracy: 0.7916\n",
      "Epoch 42/200\n",
      "40827/40827 [==============================] - 8s 205us/step - loss: 0.4534 - accuracy: 0.7901\n",
      "Epoch 43/200\n",
      "40827/40827 [==============================] - 8s 202us/step - loss: 0.4530 - accuracy: 0.7919\n",
      "Epoch 44/200\n",
      "40827/40827 [==============================] - 8s 197us/step - loss: 0.4486 - accuracy: 0.7935\n",
      "Epoch 45/200\n",
      "40827/40827 [==============================] - 9s 209us/step - loss: 0.4440 - accuracy: 0.79571s - l\n",
      "Epoch 46/200\n",
      "40827/40827 [==============================] - 8s 202us/step - loss: 0.4443 - accuracy: 0.7964\n",
      "Epoch 47/200\n",
      "40827/40827 [==============================] - 8s 201us/step - loss: 0.4401 - accuracy: 0.7994\n",
      "Epoch 48/200\n",
      "40827/40827 [==============================] - 8s 199us/step - loss: 0.4396 - accuracy: 0.7990\n",
      "Epoch 49/200\n",
      "40827/40827 [==============================] - 8s 205us/step - loss: 0.4365 - accuracy: 0.8020\n",
      "Epoch 50/200\n",
      "40827/40827 [==============================] - 8s 205us/step - loss: 0.4323 - accuracy: 0.8020\n",
      "Epoch 51/200\n",
      "40827/40827 [==============================] - 8s 191us/step - loss: 0.4288 - accuracy: 0.8052\n",
      "Epoch 52/200\n",
      "40827/40827 [==============================] - 9s 212us/step - loss: 0.4301 - accuracy: 0.8046\n",
      "Epoch 53/200\n",
      "40827/40827 [==============================] - 9s 212us/step - loss: 0.4266 - accuracy: 0.8059\n",
      "Epoch 54/200\n",
      "40827/40827 [==============================] - 8s 207us/step - loss: 0.4248 - accuracy: 0.8071\n",
      "Epoch 55/200\n",
      "40827/40827 [==============================] - 9s 213us/step - loss: 0.4241 - accuracy: 0.8060\n",
      "Epoch 56/200\n",
      "40827/40827 [==============================] - 8s 202us/step - loss: 0.4170 - accuracy: 0.8118\n",
      "Epoch 57/200\n",
      "40827/40827 [==============================] - 8s 207us/step - loss: 0.4164 - accuracy: 0.8109\n",
      "Epoch 58/200\n",
      "40827/40827 [==============================] - 8s 202us/step - loss: 0.4120 - accuracy: 0.8137\n",
      "Epoch 59/200\n",
      "40827/40827 [==============================] - 8s 198us/step - loss: 0.4124 - accuracy: 0.8152\n",
      "Epoch 60/200\n",
      "40827/40827 [==============================] - 8s 194us/step - loss: 0.4102 - accuracy: 0.8130\n",
      "Epoch 61/200\n",
      "40827/40827 [==============================] - 8s 198us/step - loss: 0.4094 - accuracy: 0.8147\n",
      "Epoch 62/200\n",
      "40827/40827 [==============================] - 8s 206us/step - loss: 0.4062 - accuracy: 0.81780s - loss: 0.4065 - accuracy: 0.\n",
      "Epoch 63/200\n",
      "40827/40827 [==============================] - 9s 218us/step - loss: 0.4021 - accuracy: 0.8182\n",
      "Epoch 64/200\n",
      "40827/40827 [==============================] - 9s 213us/step - loss: 0.4013 - accuracy: 0.8182\n",
      "Epoch 65/200\n",
      "40827/40827 [==============================] - 9s 213us/step - loss: 0.3999 - accuracy: 0.8206\n",
      "Epoch 66/200\n",
      "40827/40827 [==============================] - 8s 196us/step - loss: 0.3958 - accuracy: 0.8215\n",
      "Epoch 67/200\n",
      "40827/40827 [==============================] - 9s 215us/step - loss: 0.3944 - accuracy: 0.8227\n",
      "Epoch 68/200\n",
      "40827/40827 [==============================] - 9s 232us/step - loss: 0.3957 - accuracy: 0.8224\n",
      "Epoch 69/200\n",
      "40827/40827 [==============================] - 9s 215us/step - loss: 0.3893 - accuracy: 0.8232\n",
      "Epoch 70/200\n",
      "40827/40827 [==============================] - 9s 215us/step - loss: 0.3870 - accuracy: 0.8261\n",
      "Epoch 71/200\n",
      "40827/40827 [==============================] - 9s 213us/step - loss: 0.3861 - accuracy: 0.8270\n",
      "Epoch 72/200\n",
      "40827/40827 [==============================] - 8s 208us/step - loss: 0.3831 - accuracy: 0.8291\n",
      "Epoch 73/200\n",
      "40827/40827 [==============================] - 8s 203us/step - loss: 0.3833 - accuracy: 0.8260\n",
      "Epoch 74/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40827/40827 [==============================] - 9s 224us/step - loss: 0.3821 - accuracy: 0.8285\n",
      "Epoch 75/200\n",
      "40827/40827 [==============================] - 9s 225us/step - loss: 0.3815 - accuracy: 0.8290\n",
      "Epoch 76/200\n",
      "40827/40827 [==============================] - 9s 216us/step - loss: 0.3762 - accuracy: 0.8311\n",
      "Epoch 77/200\n",
      "40827/40827 [==============================] - 9s 209us/step - loss: 0.3775 - accuracy: 0.8287\n",
      "Epoch 78/200\n",
      "40827/40827 [==============================] - 9s 217us/step - loss: 0.3722 - accuracy: 0.8339\n",
      "Epoch 79/200\n",
      "40827/40827 [==============================] - 8s 203us/step - loss: 0.3716 - accuracy: 0.8335\n",
      "Epoch 80/200\n",
      "40827/40827 [==============================] - 8s 203us/step - loss: 0.3692 - accuracy: 0.8340\n",
      "Epoch 81/200\n",
      "40827/40827 [==============================] - 9s 209us/step - loss: 0.3632 - accuracy: 0.8389\n",
      "Epoch 82/200\n",
      "40827/40827 [==============================] - 9s 214us/step - loss: 0.3649 - accuracy: 0.8363\n",
      "Epoch 83/200\n",
      "40827/40827 [==============================] - 8s 207us/step - loss: 0.3649 - accuracy: 0.8356\n",
      "Epoch 84/200\n",
      "40827/40827 [==============================] - 8s 199us/step - loss: 0.3592 - accuracy: 0.8404\n",
      "Epoch 85/200\n",
      "40827/40827 [==============================] - 9s 214us/step - loss: 0.3566 - accuracy: 0.8399\n",
      "Epoch 86/200\n",
      "40827/40827 [==============================] - 8s 206us/step - loss: 0.3578 - accuracy: 0.8398\n",
      "Epoch 87/200\n",
      "40827/40827 [==============================] - 9s 209us/step - loss: 0.3559 - accuracy: 0.8407\n",
      "Epoch 88/200\n",
      "40827/40827 [==============================] - 9s 217us/step - loss: 0.3528 - accuracy: 0.8427\n",
      "Epoch 89/200\n",
      "40827/40827 [==============================] - 8s 206us/step - loss: 0.3505 - accuracy: 0.8434\n",
      "Epoch 90/200\n",
      "40827/40827 [==============================] - 9s 213us/step - loss: 0.3490 - accuracy: 0.8457\n",
      "Epoch 91/200\n",
      "40827/40827 [==============================] - 9s 212us/step - loss: 0.3485 - accuracy: 0.8456\n",
      "Epoch 92/200\n",
      "40827/40827 [==============================] - 9s 219us/step - loss: 0.3411 - accuracy: 0.8479\n",
      "Epoch 93/200\n",
      "40827/40827 [==============================] - 8s 204us/step - loss: 0.3465 - accuracy: 0.8436\n",
      "Epoch 94/200\n",
      "40827/40827 [==============================] - 8s 206us/step - loss: 0.3387 - accuracy: 0.8492\n",
      "Epoch 95/200\n",
      "40827/40827 [==============================] - 9s 221us/step - loss: 0.3395 - accuracy: 0.8500\n",
      "Epoch 96/200\n",
      "40827/40827 [==============================] - 9s 217us/step - loss: 0.3366 - accuracy: 0.8513\n",
      "Epoch 97/200\n",
      "40827/40827 [==============================] - 9s 217us/step - loss: 0.3378 - accuracy: 0.8495\n",
      "Epoch 98/200\n",
      "40827/40827 [==============================] - 9s 217us/step - loss: 0.3307 - accuracy: 0.8536\n",
      "Epoch 99/200\n",
      "40827/40827 [==============================] - 8s 199us/step - loss: 0.3324 - accuracy: 0.8535\n",
      "Epoch 100/200\n",
      "40827/40827 [==============================] - 8s 208us/step - loss: 0.3278 - accuracy: 0.8530\n",
      "Epoch 101/200\n",
      "40827/40827 [==============================] - 9s 213us/step - loss: 0.3268 - accuracy: 0.8561\n",
      "Epoch 102/200\n",
      "40827/40827 [==============================] - 9s 212us/step - loss: 0.3270 - accuracy: 0.8560\n",
      "Epoch 103/200\n",
      "40827/40827 [==============================] - 9s 216us/step - loss: 0.3238 - accuracy: 0.8547\n",
      "Epoch 104/200\n",
      "40827/40827 [==============================] - 9s 208us/step - loss: 0.3243 - accuracy: 0.8554\n",
      "Epoch 105/200\n",
      "40827/40827 [==============================] - 8s 203us/step - loss: 0.3174 - accuracy: 0.8596\n",
      "Epoch 106/200\n",
      "40827/40827 [==============================] - 9s 215us/step - loss: 0.3191 - accuracy: 0.8592\n",
      "Epoch 107/200\n",
      "40827/40827 [==============================] - 9s 214us/step - loss: 0.3176 - accuracy: 0.8599\n",
      "Epoch 108/200\n",
      "40827/40827 [==============================] - 9s 210us/step - loss: 0.3149 - accuracy: 0.8608\n",
      "Epoch 109/200\n",
      "40827/40827 [==============================] - 9s 208us/step - loss: 0.3158 - accuracy: 0.8603\n",
      "Epoch 110/200\n",
      "40827/40827 [==============================] - 9s 215us/step - loss: 0.3125 - accuracy: 0.8623\n",
      "Epoch 111/200\n",
      "40827/40827 [==============================] - 8s 206us/step - loss: 0.3058 - accuracy: 0.8654\n",
      "Epoch 112/200\n",
      "40827/40827 [==============================] - 8s 203us/step - loss: 0.3116 - accuracy: 0.8633\n",
      "Epoch 113/200\n",
      "40827/40827 [==============================] - 9s 211us/step - loss: 0.3053 - accuracy: 0.8671\n",
      "Epoch 114/200\n",
      "40827/40827 [==============================] - 8s 199us/step - loss: 0.3086 - accuracy: 0.8654\n",
      "Epoch 115/200\n",
      "40827/40827 [==============================] - 8s 203us/step - loss: 0.3028 - accuracy: 0.8670\n",
      "Epoch 116/200\n",
      "40827/40827 [==============================] - 9s 210us/step - loss: 0.3040 - accuracy: 0.8663\n",
      "Epoch 117/200\n",
      "40827/40827 [==============================] - 8s 200us/step - loss: 0.2980 - accuracy: 0.8710\n",
      "Epoch 118/200\n",
      "40827/40827 [==============================] - 8s 201us/step - loss: 0.3004 - accuracy: 0.8684\n",
      "Epoch 119/200\n",
      "40827/40827 [==============================] - 8s 207us/step - loss: 0.2976 - accuracy: 0.8686\n",
      "Epoch 120/200\n",
      "40827/40827 [==============================] - 8s 199us/step - loss: 0.2975 - accuracy: 0.8709\n",
      "Epoch 121/200\n",
      "40827/40827 [==============================] - 8s 202us/step - loss: 0.2936 - accuracy: 0.8715\n",
      "Epoch 122/200\n",
      "40827/40827 [==============================] - 8s 198us/step - loss: 0.2954 - accuracy: 0.87123s - loss: 0.2959 - ac\n",
      "Epoch 123/200\n",
      "40827/40827 [==============================] - 8s 199us/step - loss: 0.2932 - accuracy: 0.8699\n",
      "Epoch 124/200\n",
      "40827/40827 [==============================] - 8s 203us/step - loss: 0.2879 - accuracy: 0.8725\n",
      "Epoch 125/200\n",
      "40827/40827 [==============================] - 8s 198us/step - loss: 0.2894 - accuracy: 0.87351s - loss:\n",
      "Epoch 126/200\n",
      "40827/40827 [==============================] - 8s 203us/step - loss: 0.2884 - accuracy: 0.8728\n",
      "Epoch 127/200\n",
      "40827/40827 [==============================] - 8s 201us/step - loss: 0.2863 - accuracy: 0.8756\n",
      "Epoch 128/200\n",
      "40827/40827 [==============================] - 8s 195us/step - loss: 0.2993 - accuracy: 0.8698\n",
      "Epoch 129/200\n",
      "40827/40827 [==============================] - 8s 197us/step - loss: 0.2878 - accuracy: 0.8747\n",
      "Epoch 130/200\n",
      "40827/40827 [==============================] - 8s 197us/step - loss: 0.2832 - accuracy: 0.8775\n",
      "Epoch 131/200\n",
      "40827/40827 [==============================] - 8s 202us/step - loss: 0.2878 - accuracy: 0.8742\n",
      "Epoch 132/200\n",
      "40827/40827 [==============================] - 8s 195us/step - loss: 0.2771 - accuracy: 0.8791\n",
      "Epoch 133/200\n",
      "40827/40827 [==============================] - 9s 209us/step - loss: 0.2767 - accuracy: 0.8796\n",
      "Epoch 134/200\n",
      "40827/40827 [==============================] - 8s 201us/step - loss: 0.2770 - accuracy: 0.8791\n",
      "Epoch 135/200\n",
      "40827/40827 [==============================] - 8s 205us/step - loss: 0.2749 - accuracy: 0.8810\n",
      "Epoch 136/200\n",
      "40827/40827 [==============================] - 8s 201us/step - loss: 0.2746 - accuracy: 0.8798\n",
      "Epoch 137/200\n",
      "40827/40827 [==============================] - 9s 209us/step - loss: 0.2734 - accuracy: 0.8797\n",
      "Epoch 138/200\n",
      "40827/40827 [==============================] - 8s 202us/step - loss: 0.2711 - accuracy: 0.8824\n",
      "Epoch 139/200\n",
      "40827/40827 [==============================] - 8s 206us/step - loss: 0.2714 - accuracy: 0.8817\n",
      "Epoch 140/200\n",
      "40827/40827 [==============================] - 9s 208us/step - loss: 0.2702 - accuracy: 0.8836\n",
      "Epoch 141/200\n",
      "40827/40827 [==============================] - 8s 203us/step - loss: 0.2640 - accuracy: 0.8858\n",
      "Epoch 142/200\n",
      "40827/40827 [==============================] - 8s 196us/step - loss: 0.2642 - accuracy: 0.8853\n",
      "Epoch 143/200\n",
      "40827/40827 [==============================] - 8s 205us/step - loss: 0.2675 - accuracy: 0.88380s - loss: 0.2668 - accura\n",
      "Epoch 144/200\n",
      "40827/40827 [==============================] - 8s 207us/step - loss: 0.2651 - accuracy: 0.8837\n",
      "Epoch 145/200\n",
      "40827/40827 [==============================] - 9s 214us/step - loss: 0.2636 - accuracy: 0.8843\n",
      "Epoch 146/200\n",
      "40827/40827 [==============================] - 8s 201us/step - loss: 0.2614 - accuracy: 0.8867\n",
      "Epoch 147/200\n",
      "40827/40827 [==============================] - 9s 213us/step - loss: 0.2610 - accuracy: 0.8887\n",
      "Epoch 148/200\n",
      "40827/40827 [==============================] - 8s 207us/step - loss: 0.2541 - accuracy: 0.8918\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149/200\n",
      "40827/40827 [==============================] - 9s 209us/step - loss: 0.2576 - accuracy: 0.8885\n",
      "Epoch 150/200\n",
      "40827/40827 [==============================] - 9s 213us/step - loss: 0.2533 - accuracy: 0.8906\n",
      "Epoch 151/200\n",
      "40827/40827 [==============================] - 8s 187us/step - loss: 0.2549 - accuracy: 0.8905\n",
      "Epoch 152/200\n",
      "40827/40827 [==============================] - 8s 202us/step - loss: 0.2533 - accuracy: 0.8907\n",
      "Epoch 153/200\n",
      "40827/40827 [==============================] - 9s 216us/step - loss: 0.2521 - accuracy: 0.8908\n",
      "Epoch 154/200\n",
      "40827/40827 [==============================] - 8s 199us/step - loss: 0.2547 - accuracy: 0.8897\n",
      "Epoch 155/200\n",
      "40827/40827 [==============================] - 8s 200us/step - loss: 0.2494 - accuracy: 0.8925\n",
      "Epoch 156/200\n",
      "40827/40827 [==============================] - 8s 206us/step - loss: 0.2447 - accuracy: 0.8941\n",
      "Epoch 157/200\n",
      "40827/40827 [==============================] - 8s 202us/step - loss: 0.2463 - accuracy: 0.8955\n",
      "Epoch 158/200\n",
      "40827/40827 [==============================] - 8s 203us/step - loss: 0.2431 - accuracy: 0.8946\n",
      "Epoch 159/200\n",
      "40827/40827 [==============================] - 8s 204us/step - loss: 0.2439 - accuracy: 0.8950\n",
      "Epoch 160/200\n",
      "40827/40827 [==============================] - 9s 209us/step - loss: 0.2427 - accuracy: 0.8941\n",
      "Epoch 161/200\n",
      "40827/40827 [==============================] - 8s 201us/step - loss: 0.2384 - accuracy: 0.8963\n",
      "Epoch 162/200\n",
      "40827/40827 [==============================] - 8s 201us/step - loss: 0.2412 - accuracy: 0.8965\n",
      "Epoch 163/200\n",
      "40827/40827 [==============================] - 9s 214us/step - loss: 0.2372 - accuracy: 0.8991\n",
      "Epoch 164/200\n",
      "40827/40827 [==============================] - 8s 203us/step - loss: 0.2399 - accuracy: 0.8957\n",
      "Epoch 165/200\n",
      "40827/40827 [==============================] - 9s 229us/step - loss: 0.2345 - accuracy: 0.9000\n",
      "Epoch 166/200\n",
      "40827/40827 [==============================] - 9s 222us/step - loss: 0.2377 - accuracy: 0.8975\n",
      "Epoch 167/200\n",
      "40827/40827 [==============================] - 9s 214us/step - loss: 0.2369 - accuracy: 0.8983\n",
      "Epoch 168/200\n",
      "40827/40827 [==============================] - 8s 206us/step - loss: 0.2351 - accuracy: 0.8988\n",
      "Epoch 169/200\n",
      "40827/40827 [==============================] - 9s 220us/step - loss: 0.2314 - accuracy: 0.9003\n",
      "Epoch 170/200\n",
      "40827/40827 [==============================] - 9s 213us/step - loss: 0.2318 - accuracy: 0.9012\n",
      "Epoch 171/200\n",
      "40827/40827 [==============================] - 9s 214us/step - loss: 0.2313 - accuracy: 0.8996\n",
      "Epoch 172/200\n",
      "  768/40827 [..............................] - ETA: 29s - loss: 0.2191 - accuracy: 0.9128 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sourabh\\Anaconda3\\lib\\site-packages\\keras\\callbacks\\callbacks.py:95: RuntimeWarning: Method (on_train_batch_end) is slow compared to the batch update (0.133491). Check your callbacks.\n",
      "  % (hook_name, delta_t_median), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40827/40827 [==============================] - 9s 211us/step - loss: 0.2328 - accuracy: 0.9006\n",
      "Epoch 173/200\n",
      "40827/40827 [==============================] - 8s 206us/step - loss: 0.2292 - accuracy: 0.9026\n",
      "Epoch 174/200\n",
      "40827/40827 [==============================] - 9s 214us/step - loss: 0.2256 - accuracy: 0.9032\n",
      "Epoch 175/200\n",
      "40827/40827 [==============================] - 8s 201us/step - loss: 0.2246 - accuracy: 0.9054\n",
      "Epoch 176/200\n",
      "40827/40827 [==============================] - 8s 205us/step - loss: 0.2240 - accuracy: 0.9040\n",
      "Epoch 177/200\n",
      "40827/40827 [==============================] - 8s 202us/step - loss: 0.2187 - accuracy: 0.9071\n",
      "Epoch 178/200\n",
      "40827/40827 [==============================] - 8s 207us/step - loss: 0.2203 - accuracy: 0.90470s - loss: 0.2202 - accuracy: 0.90\n",
      "Epoch 179/200\n",
      "40827/40827 [==============================] - 8s 194us/step - loss: 0.2201 - accuracy: 0.9061\n",
      "Epoch 180/200\n",
      "40827/40827 [==============================] - 8s 205us/step - loss: 0.2209 - accuracy: 0.9045\n",
      "Epoch 181/200\n",
      "40827/40827 [==============================] - 9s 213us/step - loss: 0.2194 - accuracy: 0.9067\n",
      "Epoch 182/200\n",
      "40827/40827 [==============================] - 9s 225us/step - loss: 0.2181 - accuracy: 0.9072\n",
      "Epoch 183/200\n",
      "40827/40827 [==============================] - 9s 233us/step - loss: 0.2138 - accuracy: 0.9093\n",
      "Epoch 184/200\n",
      "40827/40827 [==============================] - 9s 227us/step - loss: 0.2192 - accuracy: 0.9082\n",
      "Epoch 185/200\n",
      "40827/40827 [==============================] - 9s 226us/step - loss: 0.2139 - accuracy: 0.9104\n",
      "Epoch 186/200\n",
      "40827/40827 [==============================] - 9s 224us/step - loss: 0.2136 - accuracy: 0.90760s - loss: 0.2137 - accuracy: 0.\n",
      "Epoch 187/200\n",
      "40827/40827 [==============================] - 9s 218us/step - loss: 0.2129 - accuracy: 0.9081\n",
      "Epoch 188/200\n",
      "40827/40827 [==============================] - 9s 219us/step - loss: 0.2099 - accuracy: 0.9110\n",
      "Epoch 189/200\n",
      "40827/40827 [==============================] - 8s 204us/step - loss: 0.2085 - accuracy: 0.9108\n",
      "Epoch 190/200\n",
      "40827/40827 [==============================] - 9s 216us/step - loss: 0.2133 - accuracy: 0.9098\n",
      "Epoch 191/200\n",
      "40827/40827 [==============================] - 9s 210us/step - loss: 0.2104 - accuracy: 0.91080s - loss: 0.2100 - accuracy\n",
      "Epoch 192/200\n",
      "40827/40827 [==============================] - 9s 216us/step - loss: 0.2094 - accuracy: 0.9113\n",
      "Epoch 193/200\n",
      "40827/40827 [==============================] - 9s 230us/step - loss: 0.2062 - accuracy: 0.9137\n",
      "Epoch 194/200\n",
      "40827/40827 [==============================] - 9s 219us/step - loss: 0.2024 - accuracy: 0.9152\n",
      "Epoch 195/200\n",
      "40827/40827 [==============================] - 9s 222us/step - loss: 0.2062 - accuracy: 0.9126\n",
      "Epoch 196/200\n",
      "40827/40827 [==============================] - 8s 199us/step - loss: 0.2030 - accuracy: 0.9141\n",
      "Epoch 197/200\n",
      "40827/40827 [==============================] - 8s 207us/step - loss: 0.2003 - accuracy: 0.91460s - loss: 0.2002 - accuracy: 0.\n",
      "Epoch 198/200\n",
      "40827/40827 [==============================] - 8s 199us/step - loss: 0.2074 - accuracy: 0.9126\n",
      "Epoch 199/200\n",
      "40827/40827 [==============================] - 9s 219us/step - loss: 0.2016 - accuracy: 0.9142\n",
      "Epoch 200/200\n",
      "40827/40827 [==============================] - 9s 229us/step - loss: 0.1966 - accuracy: 0.9162\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1f7b298fac8>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y,epochs=200,batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=model.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train=pd.read_csv('./SetA/setAA.csv')\n",
    "data_train=data_train.fillna(0)\n",
    "x_test=data_train[x].copy()\n",
    "y_test=data_train['SepsisLabel'].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3852"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_test[y_test==1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_t=y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_t[y_pred>0.5]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_t[y_pred<0.5]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "c=0\n",
    "for i in range(0,len(y_test)):\n",
    "    if y_test[i]==1 and y_t[i]==1:\n",
    "        c=c+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3426"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164835/164835 [==============================] - 7s 41us/step\n",
      "[0.9271053863914729, 0.7325810790061951]\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test)\n",
    " \n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8894080996884736"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c/len(y_test[y_test==1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./sepsissihupdate.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
